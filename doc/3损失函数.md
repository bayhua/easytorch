# 3. 损失函数

## L2损失函数

实现简单，不做说明。

L2 loss的问题是梯度的值与x的值有关，在x特别大时，会有很大的梯度，训练不稳定。

## L1损失函数

L1损失函数的形式为$loss = \sum_i |y_i - pred_i|$，导数为$sign(x)$，在$x = 0$处不可导，可以使用次梯度，取0。

L1 loss的问题与L2相反，梯度是常数，在x值很小时，梯度依然是1，如果学习率不变的话，很容易发生震荡，难以收敛到更高的精度。
